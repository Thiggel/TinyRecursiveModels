#!/bin/bash -l

#SBATCH --job-name=train
#SBATCH --output=job_logs/train_%A.txt
#SBATCH --partition=a100
#SBATCH --gres=gpu:a100:8 -C a100_80
#SBATCH --time=23:00:00
#SBATCH --nodes=1

unset SLURM_EXPORT_ENV

cd $HOME/t-jepa

. jobs/environment.sh

srun torchrun --nproc_per_node=8 train.py train.lr_scheduler_type="constant" t_jepa.load_from_checkpoint="$BASE_CACHE_DIR/checkpoints/checkpoint-2000"

sbatch jobs/train.job
